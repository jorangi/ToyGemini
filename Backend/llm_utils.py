import os
import dotenv
from google import genai
from google.genai import types
from google.api_core import exceptions

# ì´ íŒŒì¼ì—ì„œ ì§ì ‘ í•„ìš”í•œ ì„¤ì •ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
dotenv.load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ì—¬ê¸°ì„œ ìƒì„±
client = genai.Client()

async def call_gemini_agent(
    prompt_content: list[types.Content],
    use_tools: bool = True,
    temperature: float = 0.2,
    tools=None,
    available_models: list[str] = None
) -> tuple[types.GenerateContentResponse, str | None]:
    
    if available_models is None or not available_models:
        # ë§Œì•½ available_modelsê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (ì´ˆê¸° í˜¸ì¶œ ë˜ëŠ” fallback)
        available_models = [m.strip() for m in os.getenv("GEMINI_MODEL_PRIORITY_LIST").split(',')]
    
    #print("ğŸ“¤ Gemini ìš”ì²­ í”„ë¡¬í”„íŠ¸:", prompt_content)
    # (ì¶”ê°€) ë©”ì‹œì§€ íŒŒíŠ¸ ì •ê·œí™”: íŒŒì¼/ë°”ì´ë„ˆë¦¬ëŠ” í…ìŠ¤íŠ¸ë¡œ ê°•ë“±
    def _as_content(obj):
        # ì´ë¯¸ Content íƒ€ì…ì´ë©´ ê·¸ëŒ€ë¡œ
        if hasattr(obj, "parts") and hasattr(obj, "role"):
            return obj
        # ë¬¸ìì—´ì€ í…ìŠ¤íŠ¸ íŒŒíŠ¸ë¡œ ê°ìŒˆ
        if isinstance(obj, str):
            return types.Content(role="user", parts=[types.Part(text=obj)])
        # text ì†ì„±ì´ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ
        text = getattr(obj, "text", None)
        if isinstance(text, str):
            return types.Content(role="user", parts=[types.Part(text=text)])
        # dict/list ë“±ì€ ë¬¸ìì—´í™”
        return types.Content(role="user", parts=[types.Part(text=str(obj))])

    def _sanitize_messages(msgs):
        safe = []
        for m in msgs or []:
            c = _as_content(m)
            parts = []
            for p in (getattr(c, "parts", None) or []):
                # íŒŒì¼/ë°”ì´ë„ˆë¦¬/URI íŒŒíŠ¸ëŠ” í…ìŠ¤íŠ¸ë¡œ ê°•ë“±
                if getattr(p, "inline_data", None) is not None or getattr(p, "file_data", None) is not None:
                    parts.append(types.Part(text="[binary omitted]"))
                # í•¨ìˆ˜ í˜¸ì¶œ íŒŒíŠ¸ëŠ” ìœ ì§€(ë„êµ¬ í˜¸ì¶œ ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´)
                elif getattr(p, "function_call", None) is not None:
                    parts.append(types.Part(function_call=p.function_call))
                # í‰ë²”í•œ í…ìŠ¤íŠ¸
                elif getattr(p, "text", None) is not None:
                    parts.append(types.Part(text=p.text))
                else:
                    parts.append(types.Part(text=str(p)))
            if not parts:
                parts = [types.Part(text="")]
            safe.append(types.Content(role=getattr(c, "role", "user"), parts=parts))
        return safe

    # ì—¬ê¸°ì„œ í•œ ë²ˆ ì •ê·œí™”
    safe_prompt = _sanitize_messages(prompt_content)
    last_exception = None
    for model_name in available_models:
        print(f"[ğŸ”„ ëª¨ë¸ ì‹œë„] '{model_name}' ëª¨ë¸ë¡œ API í˜¸ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.")
        
        try:
            from os import getenv
            max_out = int(getenv("GEMINI_MAX_OUTPUT_TOKENS", "32768"))  # í•„ìš”ì‹œ 65536ë¡œ
            config_args = {
                "max_output_tokens": max_out,
                "temperature": temperature,
                "candidate_count": 1,               # ë¶ˆí•„ìš”í•œ í›„ë³´ ìƒì„± ê¸ˆì§€
                "response_mime_type": "text/plain", # í…ìŠ¤íŠ¸ ì „ìš©ìœ¼ë¡œ ê¸¸ê²Œ
                "safety_settings": [
                    types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_NONE'),
                ]
            }
            if use_tools and tools is not None:
                config_args['tools'] = tools

            response = await client.aio.models.generate_content(
                model=model_name, 
                contents=safe_prompt,
                config=types.GenerateContentConfig(**config_args)
            )
            
            #print("ğŸ“¥ Gemini ì‘ë‹µ ì „ì²´:", response)
            print(f"[âœ… ëª¨ë¸ ì„±ê³µ] '{model_name}' ëª¨ë¸ í˜¸ì¶œì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.")
            return response, model_name # âœ¨ ì„±ê³µí•œ ëª¨ë¸ ì´ë¦„ ë°˜í™˜

        except (exceptions.ResourceExhausted, exceptions.TooManyRequests, exceptions.ServiceUnavailable) as e:
            print(f"[âš ï¸ ëª¨ë¸ ì‹¤íŒ¨] '{model_name}' ëª¨ë¸ì˜ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            last_exception = e
            continue
        except Exception as e:
            print(f"[âŒ API ì˜¤ë¥˜] '{model_name}' ëª¨ë¸ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {type(e)}, {e}")
            last_exception = e
            continue
            
    print(f"[âŒ ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì˜ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ì˜¤ë¥˜: {last_exception}")
    error_message = f"ëª¨ë“  API ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (ìµœì¢… ì˜¤ë¥˜: {str(last_exception)})"
    
    error_action = types.FunctionCall(
        name='final_response',
        args={'answer': error_message, 'thought': "ëª¨ë“  ìš°ì„ ìˆœìœ„ì˜ ëª¨ë¸ì—ì„œ API í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ì—¬ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."}
    )
    
    error_response = types.GenerateContentResponse(
        candidates=[
            types.Candidate(
                content=types.Content(parts=[types.Part(function_call=error_action)])
            )
        ]
    )
    return error_response, None
